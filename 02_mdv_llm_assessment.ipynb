{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze metadata semantically with an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_rows = 500\n",
    "pd.options.display.max_seq_items = 500\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from utils import do_full_analysis, parse_analysis_results\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=(UserWarning, FutureWarning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "# Dataset links are composed of this baselink and the identifier for each dataset.\n",
    "BASELINK_DATASHOP = (\n",
    "    \"https://www.zh.ch/de/politik-staat/statistik-daten/datenkatalog.html#/datasets/\"\n",
    ")\n",
    "\n",
    "MDV_DATA_PATH = \"_data/01_mdv_metadata.parq\"\n",
    "\n",
    "# Default figure size for Quarto HTML output.\n",
    "FIGSIZE = (7, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we perform a specific semantic analysis of titles and descriptions in our metadata catalog with LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Retrieve data from the metadata API.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve metadata for all datasets from MDV API.\n",
    "raw = requests.get(\"https://www.web.statistik.zh.ch/ogd/daten/zhweb.json\").json()[\n",
    "    \"dataset\"\n",
    "]\n",
    "df = pd.DataFrame(pd.json_normalize(raw))\n",
    "df.to_parquet(MDV_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 445 datasets.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(MDV_DATA_PATH)\n",
    "df[\"publisher\"] = df.identifier.str.split(\"@\").str[1]\n",
    "\n",
    "# Only keep actual OGD datasets. Filter out studies.\n",
    "is_ogd = df.dropna(subset=[\"keyword\"]).keyword.apply(lambda x: \"ogd\" in x)\n",
    "df = df.loc[is_ogd[is_ogd == True].index]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "if len(df) == 0:\n",
    "    raise ValueError(\"No data retrieved.\")\n",
    "else:\n",
    "    print(f\"Retrieved {len(df)} datasets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze and score metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the 445 datasets takes about 14 minutes and costs around 5 CHF.\n",
    "\n",
    "# Be aware not to hit your OpenAI API rate limits with to many parallel requests.\n",
    "n_parallel = 10\n",
    "\n",
    "# Create a list of data rows to process in parallel.\n",
    "data_rows = [x[1] for x in list(df.iterrows())]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=n_parallel) as executor:\n",
    "    results = list(executor.map(do_full_analysis, data_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_parsed = pd.DataFrame(results, columns=[\"results_raw\"])\n",
    "results_parsed = results_parsed[\"results_raw\"].apply(parse_analysis_results)\n",
    "results_parsed = pd.concat(results_parsed.tolist(), axis=0)\n",
    "results_parsed.reset_index(drop=True, inplace=True)\n",
    "df_final = pd.concat([df, results_parsed], axis=1)\n",
    "\n",
    "cols = [\n",
    "    \"identifier\",\n",
    "    \"publisher\",\n",
    "    \"title\",\n",
    "    \"description\",\n",
    "    \"content_score\",\n",
    "    \"context_score\",\n",
    "    \"quality_score\",\n",
    "    \"spacial_score\",\n",
    "    \"content\",\n",
    "    \"context\",\n",
    "    \"quality\",\n",
    "    \"spacial\",\n",
    "]\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d\")\n",
    "df_final[cols].to_excel(f\"_results/metadata_analysis_{timestamp}.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "standard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
